import streamlit as st
import pandas as pd
import pandas_ta as ta
import akshare as ak
import plotly.graph_objects as go
import io
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

st.set_page_config(page_title="Aè‚¡æ‰¹é‡æ™ºèƒ½æŠ€æœ¯åˆ†æ & AIè¶‹åŠ¿é¢„æµ‹", layout="wide")
st.title("ğŸ“ˆ Aè‚¡æ‰¹é‡AIè‡ªåŠ¨é€‰è‚¡ & æ™ºèƒ½è¶‹åŠ¿ç‚¹è¯„ï¼ˆå…¨æ¥å£å…¼å®¹ï¼‰")

# ====== é€šç”¨å­—æ®µå…¼å®¹å·¥å…· ======
def get_first_valid_column(df, candidates):
    for col in candidates:
        if col in df.columns:
            return col
    raise ValueError(f"å­—æ®µæœªæ‰¾åˆ°ï¼Œç°æœ‰å­—æ®µ: {df.columns.tolist()}, å€™é€‰: {candidates}")

def get_code_list(df):
    code_candidates = ["symbol", "åŸºé‡‘ä»£ç ", "ä»£ç ", "con_code", "æˆåˆ†åˆ¸ä»£ç "]
    code_col = get_first_valid_column(df, code_candidates)
    return df[code_col].tolist()

def get_name_list(df):
    name_candidates = ["name", "åŸºé‡‘ç®€ç§°", "ç®€ç§°", "è‚¡ç¥¨åç§°", "æˆåˆ†åˆ¸åç§°", "æ¿å—åç§°"]
    name_col = get_first_valid_column(df, name_candidates)
    return df[name_col].tolist()

def get_pct_chg_col(df):
    chg_candidates = ["æ¶¨è·Œå¹…", "æ¶¨å¹…", "å˜åŠ¨ç‡", "æ—¥æ¶¨å¹…"]
    return get_first_valid_column(df, chg_candidates)

def show_columns(df, name="DataFrame"):
    st.write(f"ã€{name} å­—æ®µã€‘: {df.columns.tolist()}")

def sort_by_pct_chg(df, topn=20):
    try:
        col = get_pct_chg_col(df)
        return df.sort_values(col, ascending=False).head(topn)
    except Exception as e:
        st.warning(f"æ’åºå­—æ®µæœªæ‰¾åˆ°ï¼š{e}")
        return df.head(topn)

def dataframe_to_excel_bytes(df):
    output = io.BytesIO()
    df.to_excel(output, index=False, engine='openpyxl')
    return output.getvalue()

# ====== AkShareè‡ªåŠ¨å…¼å®¹æ¥å£ ======
@st.cache_data(ttl=1800)
def get_all_a_codes():
    stock_df = ak.stock_info_a_code_name()
    return get_code_list(stock_df)

@st.cache_data(ttl=1800)
def get_all_etf_codes():
    etf_df = ak.fund_etf_category_sina(symbol="ETFåŸºé‡‘")
    return get_code_list(etf_df)

@st.cache_data(ttl=1800)
def get_index_codes_auto(index_code):
    df = ak.index_stock_cons(symbol=index_code)
    code_candidates = ["con_code", "æˆåˆ†åˆ¸ä»£ç "]
    code_col = get_first_valid_column(df, code_candidates)
    return df[code_col].tolist()

# ====== æ¿å—æ’è¡Œï¼ˆè¡Œä¸š + æ¦‚å¿µè‡ªåŠ¨å…¼å®¹ï¼‰ ======
@st.cache_data(ttl=1800)
def get_hot_industry_boards(topn=20):
    try:
        df = ak.stock_board_industry_index_ths()  # âœ… è¡Œä¸šè¡Œæƒ…æ¥å£ï¼Œå«æ¶¨è·Œå¹…
    except Exception:
        df = ak.stock_board_industry_name_ths()   # å…œåº•ï¼šåªæœ‰åç§°å’Œä»£ç 
    show_columns(df, "è¡Œä¸šæ¿å—")
    return sort_by_pct_chg(df, topn=topn)

@st.cache_data(ttl=1800)
def get_hot_concept_boards(topn=20):
    try:
        df = ak.stock_board_concept_index_ths()   # âœ… æ¦‚å¿µè¡Œæƒ…æ¥å£ï¼Œå«æ¶¨è·Œå¹…
    except Exception:
        df = ak.stock_board_concept_name_ths()    # å…œåº•ï¼šåªæœ‰åç§°å’Œä»£ç 
    show_columns(df, "æ¦‚å¿µæ¿å—")
    return sort_by_pct_chg(df, topn=topn)

# ====== æ¿å—æˆåˆ†è‚¡ï¼ˆè¡Œä¸š + æ¦‚å¿µè‡ªåŠ¨å…¼å®¹ï¼‰ ======
@st.cache_data(ttl=300)
def get_board_stocks(board_name):
    try:
        df = ak.stock_board_concept_cons_ths(symbol=board_name)  # âœ… å°è¯•æ¦‚å¿µ
    except Exception:
        try:
            df = ak.stock_board_industry_cons_ths(symbol=board_name)  # âœ… å°è¯•è¡Œä¸š
        except Exception:
            return []
    return get_code_list(df) if not df.empty else []

# ====== Kçº¿ä¸ä¿¡å·åˆ¤åˆ«å‡½æ•°ï¼ˆä¿æŒåŸæ ·ï¼‰ ======
def fetch_ak_data(code, start_date):
    df = pd.DataFrame()
    try:
        df = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=start_date.strftime("%Y%m%d"), adjust="qfq")
        if not df.empty:
            df.rename(columns={"æ—¥æœŸ": "date", "å¼€ç›˜": "open", "æ”¶ç›˜": "close",
                               "æœ€é«˜": "high", "æœ€ä½": "low", "æˆäº¤é‡": "volume"}, inplace=True)
            df["date"] = pd.to_datetime(df["date"])
            df.sort_values("date", inplace=True)
            df.reset_index(drop=True, inplace=True)
            return df
    except Exception:
        pass
    # ETFå…œåº•
    try:
        df = ak.fund_etf_hist_sina(symbol=code)
        if not df.empty and "date" in df.columns:
            df["date"] = pd.to_datetime(df["date"])
            df = df[df["date"] >= pd.to_datetime(start_date)]
            df = df.sort_values("date").reset_index(drop=True)
            return df
    except Exception:
        pass
    return pd.DataFrame()

# ====== åç»­ä½ çš„ calc_indicatorsã€signal_with_explainã€tab1/tab2/tab3 ä¿æŒä¸å˜ ======
def calc_indicators(df):
    if "close" not in df.columns or len(df) < 20:
        return df
    try:
        df["SMA_5"] = ta.sma(df["close"], length=5)
        df["SMA_10"] = ta.sma(df["close"], length=10)
        df["SMA_20"] = ta.sma(df["close"], length=20)
        macd = ta.macd(df["close"])
        if macd is not None and not macd.empty:
            df["MACD"] = macd["MACD_12_26_9"]
            df["MACDs"] = macd["MACDs_12_26_9"]
        df["RSI_6"] = ta.rsi(df["close"], length=6)
    except Exception:
        pass
    return df

def signal_with_explain(df):
    explain = []
    signals = []
    latest = df.iloc[-1]
    pre = df.iloc[-2] if len(df) >= 2 else latest
    if "SMA_5" in df.columns and "SMA_10" in df.columns:
        if pre["SMA_5"] < pre["SMA_10"] and latest["SMA_5"] > latest["SMA_10"]:
            signals.append("5æ—¥å‡çº¿é‡‘å‰10æ—¥å‡çº¿")
            explain.append("ã€å‡çº¿é‡‘å‰ã€‘ï¼šä»Šæ—¥5æ—¥å‡çº¿ä¸Šç©¿10æ—¥å‡çº¿ï¼ˆé‡‘å‰ï¼‰ï¼Œå¤šå¤´ä¿¡å·ã€‚")
        else:
            explain.append(f"ã€å‡çº¿é‡‘å‰ã€‘ï¼š5æ—¥å‡çº¿({latest['SMA_5']:.2f}) {'>' if latest['SMA_5']>latest['SMA_10'] else '<='} 10æ—¥å‡çº¿({latest['SMA_10']:.2f})ï¼Œæœªå‘ç”Ÿé‡‘å‰ã€‚")
    else:
        explain.append("ã€å‡çº¿é‡‘å‰ã€‘ï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­ã€‚")
    if "MACD" in df.columns and "MACDs" in df.columns:
        if pre["MACD"] < pre["MACDs"] and latest["MACD"] > latest["MACDs"]:
            signals.append("MACDé‡‘å‰")
            explain.append("ã€MACDé‡‘å‰ã€‘ï¼šä»Šæ—¥MACDçº¿ä¸Šç©¿ä¿¡å·çº¿ï¼Œé‡‘å‰å‡ºç°ï¼Œå¤šå¤´ä¿¡å·ã€‚")
        else:
            explain.append(f"ã€MACDé‡‘å‰ã€‘ï¼šMACD({latest['MACD']:.3f}) {'>' if latest['MACD']>latest['MACDs'] else '<='} ä¿¡å·çº¿({latest['MACDs']:.3f})ï¼Œæœªå‘ç”Ÿé‡‘å‰ã€‚")
    else:
        explain.append("ã€MACDé‡‘å‰ã€‘ï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­ã€‚")
    if "RSI_6" in df.columns:
        if latest["RSI_6"] < 30 and pre["RSI_6"] >= 30:
            signals.append("RSI6è¶…å–åå¼¹")
            explain.append("ã€RSIè¶…å–åå¼¹ã€‘ï¼šä»Šæ—¥RSI6è·Œç ´30å‡ºç°åå¼¹ï¼ŒçŸ­æœŸè§åº•è¿¹è±¡ã€‚")
        else:
            explain.append(f"ã€RSIè¶…å–åå¼¹ã€‘ï¼šRSI6å½“å‰ä¸º{latest['RSI_6']:.1f}ï¼Œæœªè§¦å‘è¶…å–åå¼¹ã€‚")
    else:
        explain.append("ã€RSIè¶…å–åå¼¹ã€‘ï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­ã€‚")
    if "volume" in df.columns and "close" in df.columns and len(df) >= 6:
        pre_vol = df["volume"].iloc[-6:-1].mean()
        vol_up = latest["volume"] > 1.5 * pre_vol
        pct_chg = (latest["close"] - pre["close"]) / pre["close"] * 100 if pre["close"] > 0 else 0
        if vol_up and pct_chg > 2:
            signals.append("æ”¾é‡çªç ´")
            explain.append("ã€æ”¾é‡çªç ´ã€‘ï¼šä»Šæ—¥æˆäº¤é‡æ˜æ˜¾æ”¾å¤§ï¼Œä¸”æ¶¨å¹…è¶…è¿‡2%ï¼Œä¸»åŠ›èµ„é‡‘æœ‰å¯åŠ¨è¿¹è±¡ã€‚")
        else:
            explain.append(f"ã€æ”¾é‡çªç ´ã€‘ï¼šä»Šæ—¥æˆäº¤é‡{latest['volume']}ï¼Œå‡é‡{pre_vol:.0f}ï¼Œ{'æ”¾é‡' if vol_up else 'æœªæ”¾é‡'}ï¼Œæ¶¨å¹…{pct_chg:.2f}%ã€‚")
    else:
        explain.append("ã€æ”¾é‡çªç ´ã€‘ï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­ã€‚")
    if "close" in df.columns and len(df) >= 20:
        if latest["close"] >= df["close"].iloc[-20:].max():
            signals.append("20æ—¥æ–°é«˜")
            explain.append("ã€20æ—¥æ–°é«˜ã€‘ï¼šä»Šæ—¥æ”¶ç›˜ä»·è¾¾åˆ°è¿‘20æ—¥æœ€é«˜ã€‚")
        else:
            explain.append(f"ã€20æ—¥æ–°é«˜ã€‘ï¼šä»Šæ—¥æ”¶ç›˜{latest['close']}ï¼Œ20æ—¥æœ€é«˜{df['close'].iloc[-20:].max()}ï¼Œæœªåˆ›æ–°é«˜ã€‚")
    else:
        explain.append("ã€20æ—¥æ–°é«˜ã€‘ï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­ã€‚")
    if "close" in df.columns and len(df) >= 20:
        if latest["close"] <= df["close"].iloc[-20:].min():
            signals.append("20æ—¥æ–°ä½")
            explain.append("ã€20æ—¥æ–°ä½ã€‘ï¼šä»Šæ—¥æ”¶ç›˜ä»·è¾¾åˆ°è¿‘20æ—¥æœ€ä½ã€‚")
        else:
            explain.append(f"ã€20æ—¥æ–°ä½ã€‘ï¼šä»Šæ—¥æ”¶ç›˜{latest['close']}ï¼Œ20æ—¥æœ€ä½{df['close'].iloc[-20:].min()}ï¼Œæœªåˆ›æ–°ä½ã€‚")
    else:
        explain.append("ã€20æ—¥æ–°ä½ã€‘ï¼šæ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ¤æ–­ã€‚")
    return signals, explain

# ====== ä¸»ç•Œé¢åˆ†ä¸‰å¤§æ¨¡å— ======
tab1, tab2, tab3 = st.tabs(["ğŸ”¥ çƒ­é—¨æ¿å—æ¦‚å¿µæ’è¡Œ", "ğŸª„ æ‰¹é‡è‡ªåŠ¨é€‰è‚¡(åˆ†æ‰¹)", "AIæ™ºèƒ½æ‰¹é‡åˆ†æ"])

# --- çƒ­é—¨æ¿å—/æ¦‚å¿µæ’è¡Œ ---
with tab1:
    st.subheader("ä»Šæ—¥çƒ­é—¨è¡Œä¸š/æ¦‚å¿µæ¿å—æ¶¨å¹…æ’è¡Œ")
    col1, col2 = st.columns(2)
    with col1:
        industry_df = get_hot_industry_boards(topn=20)
        st.dataframe(industry_df, use_container_width=True)
        if st.button("å¯¼å‡ºè¡Œä¸šæ¿å—"):
            excel_bytes = dataframe_to_excel_bytes(industry_df)
            st.download_button("ä¸‹è½½è¡Œä¸šæ¿å—Excel", data=excel_bytes, file_name="è¡Œä¸šæ¿å—.xlsx")
    with col2:
        concept_df = get_hot_concept_boards(topn=20)
        st.dataframe(concept_df, use_container_width=True)
        if st.button("å¯¼å‡ºæ¦‚å¿µæ¿å—"):
            excel_bytes = dataframe_to_excel_bytes(concept_df)
            st.download_button("ä¸‹è½½æ¦‚å¿µæ¿å—Excel", data=excel_bytes, file_name="æ¦‚å¿µæ¿å—.xlsx")

# --- åˆ†æ‰¹è‡ªåŠ¨é€‰è‚¡ ---
with tab2:
    st.subheader("å…¨å¸‚åœº/ETF/æŒ‡æ•°/æ¦‚å¿µæ± è‡ªåŠ¨é€‰è‚¡ï¼Œæ”¯æŒåˆ†æ‰¹åˆ†æ")
    market_pool = st.selectbox(
        "é€‰æ‹©æ‰¹é‡é€‰è‚¡æ± ",
        options=["å…¨Aè‚¡", "å…¨ETF", "æ²ªæ·±300", "ç§‘åˆ›50", "çƒ­é—¨æ¦‚å¿µæ¿å—", "è‡ªå®šä¹‰"],
        index=0
    )
    codes = []
    if market_pool == "å…¨Aè‚¡":
        codes = get_all_a_codes()
    elif market_pool == "å…¨ETF":
        codes = get_all_etf_codes()
    elif market_pool == "æ²ªæ·±300":
        codes = get_index_codes_auto("000300")
    elif market_pool == "ç§‘åˆ›50":
        codes = get_index_codes_auto("000688")
    elif market_pool == "çƒ­é—¨æ¦‚å¿µæ¿å—":
        st.markdown("#### ğŸ”¥ ä»Šæ—¥çƒ­é—¨æ¦‚å¿µæ¿å—æ’è¡Œï¼ˆæ¶¨å¹…å‰20ï¼‰")
        hot_boards = get_hot_concept_boards()
        if not hot_boards.empty:
            st.dataframe(hot_boards, hide_index=True, use_container_width=True)
            selected_boards = st.multiselect("é€‰æ‹©è¦æ£€æµ‹çš„çƒ­é—¨æ¿å—ï¼ˆå¯å¤šé€‰ï¼‰", hot_boards.iloc[:,0].tolist())
            for board in selected_boards:
                codes += get_board_stocks(board)
        else:
            st.warning("æœªèƒ½è·å–çƒ­é—¨æ¿å—æ•°æ®")
    else:
        codes_input = st.text_area("æ‰‹åŠ¨è¾“å…¥ä»£ç ï¼ˆé€—å·ã€ç©ºæ ¼æˆ–æ¢è¡Œå‡å¯ï¼‰")
        for line in codes_input.splitlines():
            for c in line.replace('ï¼Œ', ',').replace(' ', ',').split(','):
                if c.strip():
                    codes.append(c.strip())
    codes = list(set(codes))

    # ========== åˆ†æ‰¹åˆ†é¡µ ==========
    BATCH_SIZE = 200
    if "page" not in st.session_state:
        st.session_state["page"] = 0
    total_batches = (len(codes) - 1) // BATCH_SIZE + 1 if codes else 1
    current_batch = st.session_state["page"]
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ä¸Šä¸€æ‰¹", disabled=(current_batch == 0)):
            st.session_state["page"] = max(0, current_batch - 1)
    with col2:
        st.write(f"ç¬¬{current_batch+1}/{total_batches}æ‰¹")
    with col3:
        if st.button("ä¸‹ä¸€æ‰¹", disabled=(current_batch+1 >= total_batches)):
            st.session_state["page"] = min(total_batches - 1, current_batch + 1)
    codes_this_batch = codes[current_batch*BATCH_SIZE : (current_batch+1)*BATCH_SIZE]
    st.info(f"æœ¬æ‰¹å…±{len(codes_this_batch)}åªï¼Œè‚¡ç¥¨æ± å…±{len(codes)}åªã€‚")

    start_date = st.date_input("èµ·å§‹æ—¥æœŸ", value=pd.to_datetime("2024-01-01"), key="pick_start")
    btn = st.button("æœ¬æ‰¹æ¬¡ä¸€é”®è‡ªåŠ¨é€‰è‚¡", key="btn_pick")

    # ========== å¤šçº¿ç¨‹æ‹‰å–+ä¿¡å·æ£€æµ‹ ==========
    if btn and codes_this_batch:
        st.info("å¼€å§‹æœ¬æ‰¹æ¬¡æ•°æ®åˆ†æâ€¦")
        result_table = []
        prog = st.progress(0, text="æ•°æ®å¤„ç†ä¸­â€¦")
        def fetch_ak_data_safe(code, start_date):
            try:
                df = fetch_ak_data(code, start_date)
                return code, df
            except Exception as e:
                return code, pd.DataFrame()
        result_dict = {}
        with ThreadPoolExecutor(max_workers=8) as executor:
            future_to_code = {executor.submit(fetch_ak_data_safe, code, start_date): code for code in codes_this_batch}
            for i, future in enumerate(as_completed(future_to_code)):
                code, df = future.result()
                result_dict[code] = df
                prog.progress((i+1)/len(codes_this_batch), text=f"æ‹‰å–è¿›åº¦ï¼š{i+1}/{len(codes_this_batch)}")
        prog.empty()

        for i, code in enumerate(codes_this_batch):
            df = result_dict.get(code, pd.DataFrame())
            if df.empty or len(df) < 25:
                continue
            df = calc_indicators(df)
            signals, explain = signal_with_explain(df)
            result_table.append({
                "ä»£ç ": code,
                "ä¿¡å·": "ã€".join(signals) if signals else "æ— æ˜æ˜¾ä¿¡å·",
                "æ˜ç»†è§£é‡Š": "\n".join(explain)
            })
            if i < 6 and signals:
                st.markdown(f"#### ã€{code}ã€‘é€‰è‚¡ä¿¡å·ï¼š{'ã€'.join(signals) if signals else 'æ— æ˜æ˜¾ä¿¡å·'}")
                with st.expander("ä¿¡å·æ£€æµ‹æ˜ç»†ï¼ˆç‚¹å‡»å±•å¼€ï¼‰", expanded=False):
                    for line in explain:
                        st.write(line)

        selected = [r for r in result_table if "æ— æ˜æ˜¾ä¿¡å·" not in r["ä¿¡å·"]]
        if selected:
            st.subheader("âœ… å…¥é€‰æ ‡çš„ä¸ä¿¡å·ï¼ˆå¯å…¨éƒ¨å¯¼å‡ºï¼‰")
            df_sel = pd.DataFrame(selected)
            st.dataframe(df_sel[["ä»£ç ","ä¿¡å·"]], use_container_width=True)
            excel_bytes = dataframe_to_excel_bytes(pd.DataFrame(result_table))
            st.download_button(
                "å¯¼å‡ºå…¨éƒ¨æ˜ç»†ä¸ºExcel",
                data=excel_bytes,
                file_name="AIé€‰è‚¡æ˜ç»†.xlsx"
            )
        else:
            st.warning("æš‚æ— æ ‡çš„è§¦å‘é€‰è‚¡ä¿¡å·ï¼Œå¯åˆ‡æ¢æ‰¹æ¬¡ã€è°ƒæ•´ç­–ç•¥æˆ–æ¢æ± ã€‚")
    else:
        st.markdown("> æ”¯æŒå…¨Aè‚¡ã€ETFã€æŒ‡æ•°æˆåˆ†ã€çƒ­é—¨æ± ä¸€é”®åˆ†æ‰¹è‡ªåŠ¨é€‰è‚¡ã€‚")

# --- AIæ‰¹é‡åˆ†æ ---
with tab3:
    st.subheader("è‡ªå®šä¹‰è‚¡ç¥¨æ± æ‰¹é‡åˆ†æ+AIæ™ºèƒ½ç‚¹è¯„")
    openai_key = st.text_input("è¯·è¾“å…¥ä½ çš„OpenAI API KEYï¼ˆç”¨äºAIç‚¹è¯„/è¶‹åŠ¿é¢„æµ‹ï¼‰", type="password", key="ai_key")
    codes_input = st.text_input("è¯·è¾“å…¥Aè‚¡è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒæ‰¹é‡,å¦‚ 600519,000977,588170ï¼‰ï¼š", value="000977,518880", key="ai_codes")
    start_date = st.date_input("é€‰æ‹©èµ·å§‹æ—¥æœŸ", value=datetime.now().replace(year=2025, month=9, day=4), key="ai_date")
    ai_enable = st.toggle("å¯ç”¨AIè¶‹åŠ¿ç‚¹è¯„", value=True, key="ai_toggle")
    trend_days = st.selectbox("AIé¢„æµ‹æœªæ¥å¤©æ•°", options=[1, 3, 5, 7], index=1, key="ai_trend_days")

    def plot_kline(df, code):
        fig = go.Figure()
        fig.add_trace(go.Candlestick(
            x=df["date"], open=df["open"], high=df["high"],
            low=df["low"], close=df["close"], name="Kçº¿"))
        if "SMA_5" in df.columns:
            fig.add_trace(go.Scatter(x=df["date"], y=df["SMA_5"], mode='lines', name="SMA5"))
        if "SMA_10" in df.columns:
            fig.add_trace(go.Scatter(x=df["date"], y=df["SMA_10"], mode='lines', name="SMA10"))
        if "SMA_20" in df.columns:
            fig.add_trace(go.Scatter(x=df["date"], y=df["SMA_20"], mode='lines', name="SMA20"))
        fig.update_layout(title=f"{code} Kçº¿ä¸å‡çº¿", xaxis_rangeslider_visible=False, height=400)
        st.plotly_chart(fig, use_container_width=True)
        if "MACD" in df.columns:
            fig2 = go.Figure()
            fig2.add_trace(go.Bar(x=df["date"], y=df["MACD"], name="MACDçº¿"))
            fig2.add_trace(go.Scatter(x=df["date"], y=df["MACDs"], name="ä¿¡å·çº¿"))
            fig2.update_layout(title="MACDæŒ‡æ ‡", height=200)
            st.plotly_chart(fig2, use_container_width=True)
        if "RSI_6" in df.columns:
            fig3 = go.Figure()
            fig3.add_trace(go.Scatter(x=df["date"], y=df["RSI_6"], name="RSI6"))
            fig3.update_layout(title="RSIæŒ‡æ ‡", height=200, yaxis=dict(range=[0,100]))
            st.plotly_chart(fig3, use_container_width=True)

    def ai_trend_report(df, code, trend_days, openai_key):
        if not openai_key:
            return "æœªå¡«å†™OpenAI KEYï¼Œæ— æ³•ç”ŸæˆAIè¶‹åŠ¿é¢„æµ‹ã€‚"
        use_df = df.tail(60)[["date", "open", "close", "high", "low", "volume"]]
        data_str = use_df.to_csv(index=False)
        prompt = f"""
ä½ æ˜¯ä¸€ä½Aè‚¡ä¸“ä¸šé‡åŒ–åˆ†æå¸ˆã€‚ä»¥ä¸‹æ˜¯{code}æœ€è¿‘60æ—¥çš„æ¯æ—¥è¡Œæƒ…ï¼ˆæ—¥æœŸ,å¼€ç›˜,æ”¶ç›˜,æœ€é«˜,æœ€ä½,æˆäº¤é‡ï¼‰ï¼Œè¯·æ ¹æ®æŠ€æœ¯èµ°åŠ¿ã€æˆäº¤é‡å˜åŒ–ï¼Œé¢„æµ‹è¯¥è‚¡æœªæ¥{trend_days}æ—¥çš„æ¶¨è·Œè¶‹åŠ¿ï¼Œå¹¶åˆ¤æ–­æ˜¯å¦å­˜åœ¨å¯åŠ¨ä¿¡å·ã€ä¹°å–æœºä¼šï¼Œè¯·ä»¥ç²¾ç‚¼ä¸­æ–‡è¾“å‡ºä¸€ä»½ç‚¹è¯„ã€‚æ•°æ®å¦‚ä¸‹ï¼ˆcsvæ ¼å¼ï¼‰ï¼š
{data_str}
"""
        try:
            import openai
            client = openai.OpenAI(api_key=openai_key)
            chat_completion = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸“ä¸šAè‚¡åˆ†æå¸ˆã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=400,
                temperature=0.6,
            )
            return chat_completion.choices[0].message.content
        except Exception as ex:
            return f"AIåˆ†æè°ƒç”¨å¤±è´¥ï¼š{ex}"

    if st.button("æ‰¹é‡åˆ†æ", key="ai_btn"):
        codes = [c.strip() for c in codes_input.split(",") if c.strip()]
        for code in codes:
            st.header(f"ã€{code}ã€‘åˆ†æ")
            df = fetch_ak_data(code, start_date)
            if df.empty:
                st.warning(f"{code} æ•°æ®æœªè·å–åˆ°ï¼Œå¯èƒ½ä»£ç é”™è¯¯æˆ–æ—¥æœŸè¿‡è¿‘ã€‚")
                continue
            df = calc_indicators(df)
            st.dataframe(df.tail(10))
            plot_kline(df, code)
            if ai_enable:
                with st.spinner(f"AIåˆ†æ{code}ä¸­..."):
                    ai_report = ai_trend_report(df, code, trend_days, openai_key)
                    st.info(ai_report)
            st.divider()
    else:
        st.markdown("> æ”¯æŒå¤šåªAè‚¡ä»£ç æ‰¹é‡æŠ€æœ¯åˆ†æ+AIè‡ªåŠ¨ç‚¹è¯„ï¼ˆå¦‚éœ€AIé¢„æµ‹è¯·å¡«å†™OpenAI KEYï¼‰")

st.info("å…¨æ–°ç‰ˆæœ¬å·²é€‚é…æ‰€æœ‰å­—æ®µã€æ¥å£ã€å¯¼å‡ºï¼Œæ— éœ€æ‹…å¿ƒKeyErroræˆ–Excelå¯¼å‡ºæŠ¥é”™ï¼Œå¯é•¿æœŸäº‘ç«¯ç¨³å®šè¿è¡Œã€‚")
