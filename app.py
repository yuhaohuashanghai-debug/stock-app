import streamlit as st
import pandas as pd
import akshare as ak
import plotly.graph_objects as go
from datetime import datetime
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import io

st.set_page_config(page_title="Aè‚¡æ‰¹é‡æ™ºèƒ½æŠ€æœ¯åˆ†æ & AIè¶‹åŠ¿é¢„æµ‹", layout="wide")
st.title("ğŸ“ˆ Aè‚¡æ‰¹é‡AIè‡ªåŠ¨é€‰è‚¡ & æ™ºèƒ½è¶‹åŠ¿ç‚¹è¯„")

# ====== æ•°æ®æºæ¥å£å…¼å®¹å±‚ ======
@st.cache_data(show_spinner=False)
def get_index_codes(index_code):
    """æ‹‰å–æŒ‡æ•°æˆåˆ†è‚¡åˆ—è¡¨ï¼Œå…¼å®¹å­—æ®µæ–°æ—§ç‰ˆæœ¬"""
    try:
        df = ak.index_stock_cons(symbol=index_code)
        if "con_code" in df.columns:
            return df["con_code"].tolist()
        elif "æˆåˆ†åˆ¸ä»£ç " in df.columns:
            return df["æˆåˆ†åˆ¸ä»£ç "].tolist()
        else:
            st.warning("æŒ‡æ•°æˆåˆ†è‚¡æ•°æ®å­—æ®µå¼‚å¸¸ï¼")
            return []
    except Exception as e:
        st.warning(f"æ‹‰å–æŒ‡æ•°æˆåˆ†è‚¡å¤±è´¥: {e}")
        return []

@st.cache_data(show_spinner=False)
def get_all_etf_codes():
    """æ‹‰å–æ‰€æœ‰ETFä»£ç """
    try:
        etf_df = ak.fund_etf_category_sina(symbol="ETFåŸºé‡‘")
        if "symbol" in etf_df.columns:
            return etf_df["symbol"].tolist()
        elif "ä»£ç " in etf_df.columns:
            return etf_df["ä»£ç "].tolist()
        else:
            st.warning("ETFæ•°æ®ç»“æ„å¼‚å¸¸ï¼")
            return []
    except Exception as e:
        st.warning(f"ETFæ‹‰å–å¤±è´¥: {e}")
        return []

@st.cache_data(show_spinner=False)
def get_all_a_codes_exclude_indexes():
    """æ‹‰å–Aè‚¡å…¨å¸‚åœºä»£ç ï¼Œå¹¶è‡ªåŠ¨å‰”é™¤æ²ªæ·±300ã€ç§‘åˆ›50æˆåˆ†è‚¡"""
    try:
        all_a = ak.stock_info_a_code_name()["code"].tolist()
        hs300 = set(get_index_codes("000300"))
        kc50 = set(get_index_codes("000688"))
        only_a = [x for x in all_a if x not in hs300 and x not in kc50]
        return only_a
    except Exception as e:
        st.warning(f"Aè‚¡æ‹‰å–å¤±è´¥: {e}")
        return []

@st.cache_data(ttl=300, show_spinner=False)
def get_hot_concept_boards(topn=20):
    """æ‹‰å–çƒ­é—¨æ¦‚å¿µæ¿å—æ’è¡Œï¼Œå­—æ®µå…¼å®¹"""
    try:
        df = ak.stock_board_concept_name_ths()
        name_col = "æ¿å—åç§°" if "æ¿å—åç§°" in df.columns else ("æ¦‚å¿µåç§°" if "æ¦‚å¿µåç§°" in df.columns else None)
        pct_col = "æ¶¨è·Œå¹…" if "æ¶¨è·Œå¹…" in df.columns else ("æ¶¨å¹…" if "æ¶¨å¹…" in df.columns else None)
        if name_col and pct_col:
            hot_df = df.sort_values(pct_col, ascending=False).head(topn)
            return hot_df[[name_col, pct_col]]
        else:
            st.warning("çƒ­é—¨æ¦‚å¿µæ¿å—æ•°æ®å­—æ®µå¼‚å¸¸ï¼")
            return pd.DataFrame()
    except Exception as e:
        st.warning(f"æ‹‰å–çƒ­é—¨æ¿å—å¤±è´¥: {e}")
        return pd.DataFrame()

@st.cache_data(ttl=300, show_spinner=False)
def get_board_stocks(board_name):
    """æ‹‰å–æŒ‡å®šæ¿å—æˆåˆ†è‚¡"""
    try:
        df = ak.stock_board_concept_cons_ths(symbol=board_name)
        if "ä»£ç " in df.columns:
            return df["ä»£ç "].tolist()
        elif "è‚¡ç¥¨ä»£ç " in df.columns:
            return df["è‚¡ç¥¨ä»£ç "].tolist()
        else:
            return []
    except Exception:
        return []

# ========== æ ¸å¿ƒæ•°æ®æ‹‰å–ä¸ä¿¡å·å‡½æ•°ï¼ˆéœ€è¡¥å…¨/æ›¿æ¢ï¼‰ ==========
def fetch_ak_data(code, start_date):
    """Aè‚¡ã€ETFè‡ªåŠ¨åˆ¤åˆ«æ‹‰Kçº¿ï¼Œå…¼å®¹å­—æ®µå˜åŒ–ä¸å¼‚å¸¸"""
    try:
        sdate = str(start_date).replace("-", "")
        # ETFä¸€èˆ¬ä»¥51/15/56/588ç­‰å¼€å¤´ï¼Œè‡ªåŠ¨åˆ‡æ¢æ¥å£
        if code.startswith(("51", "15", "56", "58")) and len(code) == 6:
            # ETFï¼šç”¨æ–°æµªETFæ¥å£
            df = ak.fund_etf_hist_sina(symbol=code)
            if df.empty:
                st.warning(f"{code} ETFæ— å†å²æ•°æ®")
                return pd.DataFrame()
            # å­—æ®µæ ‡å‡†åŒ–
            df.rename(columns={"date": "date", "close": "close", "open": "open",
                               "high": "high", "low": "low", "volume": "volume"}, inplace=True)
            # ETFæ¥å£æ—¥æœŸæ˜¯stræ ¼å¼
            df["date"] = pd.to_datetime(df["date"])
            df = df[df["date"] >= pd.to_datetime(start_date)]
            return df
        else:
            # æ™®é€šAè‚¡
            df = ak.stock_zh_a_hist(symbol=code, period="daily", start_date=sdate, adjust="qfq")
            if df.empty:
                st.warning(f"{code} æ²¡æœ‰æ•°æ®ï¼Œå¯èƒ½æ˜¯æ–°è‚¡æˆ–ä»£ç é”™è¯¯ã€‚")
                return pd.DataFrame()
            # å­—æ®µå…¼å®¹
            rename_dict = {"æ—¥æœŸ": "date", "å¼€ç›˜": "open", "æ”¶ç›˜": "close", "æœ€é«˜": "high",
                           "æœ€ä½": "low", "æˆäº¤é‡": "volume"}
            for k, v in rename_dict.items():
                if k in df.columns:
                    df.rename(columns={k: v}, inplace=True)
            df["date"] = pd.to_datetime(df["date"])
            return df
    except Exception as ex:
        st.warning(f"{code} æ‹‰å–å¤±è´¥: {ex}")
        return pd.DataFrame()

# ----------- ä»¥ä¸‹ä¸¤ä¸ªå‡½æ•°ä½ å¯ä»¥ç”¨è‡ªå·±çš„å®ç°ï¼Œä¹Ÿå¯ç”¨å¦‚ä¸‹ç®€å•æ¨¡æ¿ -----------
def calc_indicators(df):
    """ç®€å•æŒ‡æ ‡è®¡ç®—ï¼Œå¯ç”¨pandas_taç­‰è¡¥å……å®Œå–„"""
    df = df.copy()
    df["SMA_5"] = df["close"].rolling(5).mean()
    df["SMA_10"] = df["close"].rolling(10).mean()
    df["SMA_20"] = df["close"].rolling(20).mean()
    # MACDç®€å•è®¡ç®—
    df["EMA_12"] = df["close"].ewm(span=12).mean()
    df["EMA_26"] = df["close"].ewm(span=26).mean()
    df["MACD"] = df["EMA_12"] - df["EMA_26"]
    df["MACDs"] = df["MACD"].ewm(span=9).mean()
    df["MACDh"] = df["MACD"] - df["MACDs"]
    # RSIç®€å•è®¡ç®—
    df["RSI_6"] = ta.rsi(df["close"], length=6)
    df["RSI_12"] = ta.rsi(df["close"], length=12)
    return df

def signal_with_explain(df):
    """æŠ€æœ¯é¢ä¿¡å·åˆ¤åˆ«ï¼ˆæ¼”ç¤ºç‰ˆï¼‰ï¼Œå¯æŒ‰éœ€è‡ªå®šä¹‰å¢å¼º"""
    signals, explain = [], []
    # MACDé‡‘å‰
    if df["MACDh"].iloc[-1] > 0 and df["MACDh"].iloc[-2] < 0:
        signals.append("MACDé‡‘å‰")
        explain.append("MACDæŸ±å­åˆšåˆšç¿»çº¢ï¼Œå¯èƒ½å‡ºç°åè½¬ä¸Šæ¶¨ã€‚")
    # å‡çº¿å¤šå¤´
    if df["SMA_5"].iloc[-1] > df["SMA_10"].iloc[-1] > df["SMA_20"].iloc[-1]:
        signals.append("å‡çº¿å¤šå¤´æ’åˆ—")
        explain.append("çŸ­ä¸­é•¿æœŸå‡çº¿å‘ˆå¤šå¤´ï¼Œè¶‹åŠ¿å‘ä¸Šã€‚")
    # RSIè¶…å–
    if df["RSI_6"].iloc[-1] < 30:
        signals.append("RSIè¶…å–åå¼¹")
        explain.append("RSIçŸ­æœŸå¤„äºè¶…å–åŒºï¼ŒæŠ€æœ¯åå¼¹æ¦‚ç‡å¤§ã€‚")
    return signals, explain

# =================== Streamlitä¸»ç•Œé¢ ===================
tab1, tab2 = st.tabs(["ğŸª„ æ‰¹é‡è‡ªåŠ¨é€‰è‚¡(åˆ†æ‰¹)", "ä¸ªè‚¡æ‰¹é‡åˆ†æ+AIç‚¹è¯„"])

with tab1:
    st.subheader("å…¨Aè‚¡/æ²ªæ·±300/ç§‘åˆ›50/ETF/çƒ­é—¨æ¿å—è‡ªåŠ¨é€‰è‚¡ï¼Œè¶‹åŠ¿è‚¡æ± ä¸“å±æ¿å—")
    market_pool = st.selectbox(
        "é€‰æ‹©æ‰¹é‡é€‰è‚¡æ± ",
        options=["å…¨Aè‚¡(ä¸å«æ²ªæ·±300ã€ç§‘åˆ›50)", "æ²ªæ·±300", "ç§‘åˆ›50", "å…¨ETF", "çƒ­é—¨æ¦‚å¿µæ¿å—", "è‡ªå®šä¹‰"],
        index=0
    )
    codes = []
    show_desc = ""
    if market_pool.startswith("å…¨Aè‚¡"):
        codes = get_all_a_codes_exclude_indexes()
        show_desc = "ï¼ˆå…¨Aè‚¡ï¼Œå·²å‰”é™¤æ²ªæ·±300ä¸ç§‘åˆ›50æˆåˆ†è‚¡ï¼‰"
    elif market_pool == "æ²ªæ·±300":
        codes = get_index_codes("000300")
        show_desc = "ï¼ˆæ²ªæ·±300æŒ‡æ•°æˆåˆ†è‚¡ï¼‰"
    elif market_pool == "ç§‘åˆ›50":
        codes = get_index_codes("000688")
        show_desc = "ï¼ˆç§‘åˆ›50æŒ‡æ•°æˆåˆ†è‚¡ï¼‰"
    elif market_pool == "å…¨ETF":
        codes = get_all_etf_codes()
        show_desc = "ï¼ˆå…¨ETFåŸºé‡‘ï¼‰"
    elif market_pool == "çƒ­é—¨æ¦‚å¿µæ¿å—":
        st.markdown("#### ğŸ”¥ ä»Šæ—¥çƒ­é—¨æ¦‚å¿µæ¿å—æ’è¡Œï¼ˆæ¶¨å¹…å‰20ï¼‰")
        hot_boards = get_hot_concept_boards()
        if not hot_boards.empty:
            st.dataframe(hot_boards, hide_index=True, use_container_width=True)
            selected_boards = st.multiselect("é€‰æ‹©è¦æ£€æµ‹çš„çƒ­é—¨æ¿å—ï¼ˆå¯å¤šé€‰ï¼‰", hot_boards.iloc[:,0].tolist())
            for board in selected_boards:
                codes += get_board_stocks(board)
            show_desc = "ï¼ˆçƒ­é—¨æ¦‚å¿µæ¿å—æ± ï¼Œæˆåˆ†è‚¡åˆå¹¶ï¼‰"
        else:
            st.warning("æœªèƒ½è·å–çƒ­é—¨æ¿å—æ•°æ®")
    else:
        codes_input = st.text_area("æ‰‹åŠ¨è¾“å…¥ä»£ç ï¼ˆé€—å·ã€ç©ºæ ¼æˆ–æ¢è¡Œå‡å¯ï¼‰")
        for line in codes_input.splitlines():
            for c in line.replace('ï¼Œ', ',').replace(' ', ',').split(','):
                if c.strip():
                    codes.append(c.strip())
        show_desc = "ï¼ˆè‡ªå®šä¹‰æ± ï¼‰"
    codes = list(set(codes))
    st.info(f"{show_desc} é€‰è‚¡æ± å…±è®¡ {len(codes)} åªæ ‡çš„ã€‚")

    # ======== åˆ†æ‰¹åˆ†é¡µ ========
    BATCH_SIZE = 200
    if "page" not in st.session_state:
        st.session_state["page"] = 0
    total_batches = (len(codes) - 1) // BATCH_SIZE + 1 if codes else 1
    current_batch = st.session_state["page"]
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("ä¸Šä¸€æ‰¹", disabled=(current_batch == 0)):
            st.session_state["page"] = max(0, current_batch - 1)
    with col2:
        st.write(f"ç¬¬{current_batch+1}/{total_batches}æ‰¹")
    with col3:
        if st.button("ä¸‹ä¸€æ‰¹", disabled=(current_batch+1 >= total_batches)):
            st.session_state["page"] = min(total_batches - 1, current_batch + 1)
    codes_this_batch = codes[current_batch*BATCH_SIZE : (current_batch+1)*BATCH_SIZE]
    st.info(f"æœ¬æ‰¹å…±{len(codes_this_batch)}åªï¼Œè‚¡ç¥¨æ± å…±{len(codes)}åªã€‚")

    start_date = st.date_input("èµ·å§‹æ—¥æœŸ", value=pd.to_datetime("2024-01-01"), key="pick_start")
    openai_key = st.text_input("å¦‚éœ€AIæ‰¹é‡è¶‹åŠ¿ç‚¹è¯„ï¼Œè¯·è¾“å…¥OpenAI KEY", type="password", key="tab1_ai_key")
    ai_batch = st.toggle("æ‰¹é‡AIæ™ºèƒ½ç‚¹è¯„", value=True, key="ai_batch_tab1")
    trend_days = st.selectbox("AIé¢„æµ‹æœªæ¥å¤©æ•°", options=[1, 3, 5, 7], index=1, key="tab1_trend_days")
    btn = st.button("æœ¬æ‰¹æ¬¡ä¸€é”®è‡ªåŠ¨é€‰è‚¡", key="btn_pick")

    # ========== å¤šçº¿ç¨‹å¹¶å‘æ‹‰å–Kçº¿ + ä¿¡å·AIæ™ºèƒ½ç‚¹è¯„ ==========
    if btn and codes_this_batch:
        st.info("å¼€å§‹æœ¬æ‰¹æ¬¡æ•°æ®åˆ†æâ€¦")
        result_table = []
        prog = st.progress(0, text="æ•°æ®å¤„ç†ä¸­â€¦")
        def fetch_ak_data_safe(code, start_date):
            try:
                time.sleep(0.3) # é™é€Ÿï¼Œé˜²å°IP
                df = fetch_ak_data(code, start_date)
                return code, df
            except Exception as e:
                return code, pd.DataFrame()
        result_dict = {}
        with ThreadPoolExecutor(max_workers=8) as executor:
            future_to_code = {executor.submit(fetch_ak_data_safe, code, start_date): code for code in codes_this_batch}
            for i, future in enumerate(as_completed(future_to_code)):
                code, df = future.result()
                result_dict[code] = df
                prog.progress((i+1)/len(codes_this_batch), text=f"æ‹‰å–è¿›åº¦ï¼š{i+1}/{len(codes_this_batch)}")
        prog.empty()

        # 2. ä¿¡å·åˆ¤åˆ«å’ŒAIç‚¹è¯„ï¼ˆä»…å¯¹æœ‰ä¿¡å·è‚¡AIï¼‰
        trend_stock_pool = []
        for i, code in enumerate(codes_this_batch):
            df = result_dict.get(code, pd.DataFrame())
            if df.empty or len(df) < 25:
                continue
            df = calc_indicators(df)
            signals, explain = signal_with_explain(df)
            ai_result = ""
            if ai_batch and openai_key and signals:
                with st.spinner(f"AIåˆ†æ{code}ä¸­..."):
                    ai_result = ai_trend_report(df, code, trend_days, openai_key)
                    time.sleep(1.2)  # é™é€Ÿï¼Œé˜²æ­¢è¢«å°
            row = {
                "ä»£ç ": code,
                "ä¿¡å·": "ã€".join(signals) if signals else "æ— æ˜æ˜¾ä¿¡å·",
                "æ˜ç»†è§£é‡Š": "\n".join(explain),
                "AIç‚¹è¯„": ai_result
            }
            result_table.append(row)
            if signals:
                trend_stock_pool.append(row)
            if i < 6 and signals:
                st.markdown(f"#### ã€{code}ã€‘é€‰è‚¡ä¿¡å·ï¼š{'ã€'.join(signals)}")
                with st.expander("ä¿¡å·æ£€æµ‹æ˜ç»†ï¼ˆç‚¹å‡»å±•å¼€ï¼‰", expanded=False):
                    for line in explain:
                        st.write(line)
                if ai_result:
                    st.info(f"AIç‚¹è¯„ï¼š{ai_result}")

        # ========= è¶‹åŠ¿è‚¡æ± ä¸“å±æ¿å— =========
        st.markdown("---")
        st.subheader("ğŸš© æœ¬æ‰¹è¶‹åŠ¿è‚¡æ± ï¼ˆæ‰€æœ‰æ£€æµ‹å‡ºä¿¡å·çš„æ ‡çš„ï¼‰")
        if trend_stock_pool:
            df_pool = pd.DataFrame(trend_stock_pool)
            st.dataframe(df_pool[["ä»£ç ", "ä¿¡å·", "AIç‚¹è¯„"]], use_container_width=True)
            # æ”¯æŒå¯¼å‡ºè¶‹åŠ¿è‚¡æ± 
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df_pool.to_excel(writer, index=False)
            st.download_button(
                "å¯¼å‡ºè¶‹åŠ¿è‚¡æ± ä¸ºExcel",
                data=output.getvalue(),
                file_name="è¶‹åŠ¿è‚¡æ± .xlsx"
            )
        else:
            st.info("æœ¬æ‰¹æš‚æ— è¶‹åŠ¿ä¿¡å·è‚¡ã€‚")

        # ========= å…¨éƒ¨ç»“æœå¯¼å‡º =========
        st.markdown("---")
        with st.expander("å¯¼å‡ºå…¨éƒ¨æ˜ç»†ï¼ˆå«æ— ä¿¡å·ï¼‰", expanded=False):
            df_all = pd.DataFrame(result_table)
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                df_all.to_excel(writer, index=False)
            st.download_button(
                "å¯¼å‡ºå…¨éƒ¨åˆ†ææ˜ç»†ä¸ºExcel",
                data=output.getvalue(),
                file_name="AIé€‰è‚¡æ˜ç»†_å…¨éƒ¨å«æ— ä¿¡å·.xlsx"
            )
    else:
        st.markdown("> æ”¯æŒå…¨Aè‚¡ï¼ˆå·²å‰”é™¤æ²ªæ·±300/ç§‘åˆ›50ï¼‰ã€æ²ªæ·±300ã€ç§‘åˆ›50ã€ETFã€çƒ­é—¨æ¿å—ä¸€é”®åˆ†æ‰¹è‡ªåŠ¨é€‰è‚¡+AIè¶‹åŠ¿ç‚¹è¯„ã€‚è¶‹åŠ¿ä¿¡å·è‚¡é«˜äº®è¾“å‡ºä¸“å±æ¿å—ã€‚")

# ================== Tab2ï¼šä¸ªè‚¡æ‰¹é‡åˆ†æ+AI ==================
with tab2:
    st.subheader("è‡ªå®šä¹‰è‚¡ç¥¨æ± æ‰¹é‡åˆ†æ+AIæ™ºèƒ½ç‚¹è¯„")
    openai_key = st.text_input("è¯·è¾“å…¥ä½ çš„OpenAI API KEYï¼ˆç”¨äºAIç‚¹è¯„/è¶‹åŠ¿é¢„æµ‹ï¼‰", type="password", key="ai_key")
    codes_input = st.text_input("è¯·è¾“å…¥Aè‚¡è‚¡ç¥¨ä»£ç ï¼ˆæ”¯æŒæ‰¹é‡,å¦‚ 600519,000977,588170ï¼‰ï¼š", value="000977,518880", key="ai_codes")
    start_date = st.date_input("é€‰æ‹©èµ·å§‹æ—¥æœŸ", value=datetime.now().replace(year=2025, month=9, day=4), key="ai_date")
    ai_enable = st.toggle("å¯ç”¨AIè¶‹åŠ¿ç‚¹è¯„", value=True, key="ai_toggle")
    trend_days = st.selectbox("AIé¢„æµ‹æœªæ¥å¤©æ•°", options=[1, 3, 5, 7], index=1, key="ai_trend_days")

    def plot_kline(df, code):
    fig = go.Figure()
    fig.add_trace(go.Candlestick(
        x=df["date"], open=df["open"], high=df["high"],
        low=df["low"], close=df["close"], name="Kçº¿"))
    if "SMA_5" in df.columns:
        fig.add_trace(go.Scatter(x=df["date"], y=df["SMA_5"], mode='lines', name="SMA5"))
    if "SMA_10" in df.columns:
        fig.add_trace(go.Scatter(x=df["date"], y=df["SMA_10"], mode='lines', name="SMA10"))
    if "SMA_20" in df.columns:
        fig.add_trace(go.Scatter(x=df["date"], y=df["SMA_20"], mode='lines', name="SMA20"))
    fig.update_layout(title=f"{code} Kçº¿ä¸å‡çº¿", xaxis_rangeslider_visible=False, height=400)
    st.plotly_chart(fig, use_container_width=True)

    # MACD
    if "MACD" in df.columns and "MACDh" in df.columns and "MACDs" in df.columns:
        fig2 = go.Figure()
        fig2.add_trace(go.Bar(x=df["date"], y=df["MACDh"], name="MACDæŸ±"))
        fig2.add_trace(go.Scatter(x=df["date"], y=df["MACD"], name="MACDçº¿"))
        fig2.add_trace(go.Scatter(x=df["date"], y=df["MACDs"], name="ä¿¡å·çº¿"))
        fig2.update_layout(title="MACDæŒ‡æ ‡", height=200)
        st.plotly_chart(fig2, use_container_width=True)

    # RSI
    if "RSI_6" in df.columns:
        fig3 = go.Figure()
        fig3.add_trace(go.Scatter(x=df["date"], y=df["RSI_6"], name="RSI6"))
        if "RSI_12" in df.columns:
            fig3.add_trace(go.Scatter(x=df["date"], y=df["RSI_12"], name="RSI12"))
        fig3.update_layout(title="RSIæŒ‡æ ‡", height=200, yaxis=dict(range=[0,100]))
        st.plotly_chart(fig3, use_container_width=True)
